{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCBS_2021-2023_Full.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Tiba\\anaconda3\\envs\\EDA\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tiba\\anaconda3\\envs\\EDA\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tiba\\anaconda3\\envs\\EDA\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Tiba\\anaconda3\\envs\\EDA\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df =pd.read_csv(\"CBS_2021-2023_Full.csv\", sep =',')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info of the DataFrame:\n",
      " \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10693997 entries, 0 to 10693996\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ride_id             object \n",
      " 1   rideable_type       object \n",
      " 2   started_at          object \n",
      " 3   ended_at            object \n",
      " 4   start_station_name  object \n",
      " 5   start_station_id    object \n",
      " 6   end_station_name    object \n",
      " 7   end_station_id      object \n",
      " 8   start_lat           float64\n",
      " 9   start_lng           float64\n",
      " 10  end_lat             float64\n",
      " 11  end_lng             float64\n",
      " 12  member_casual       object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "# Check info and dtypes of the dataframe\n",
    "print(\"Info of the DataFrame:\\n\", '\\n')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                object\n",
       "rideable_type          object\n",
       "started_at             object\n",
       "ended_at               object\n",
       "start_station_name     object\n",
       "start_station_id       object\n",
       "end_station_name       object\n",
       "end_station_id         object\n",
       "start_lat             float64\n",
       "start_lng             float64\n",
       "end_lat               float64\n",
       "end_lng               float64\n",
       "member_casual          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start_lat</th>\n",
       "      <td>10693995.0</td>\n",
       "      <td>38.903306</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>38.76</td>\n",
       "      <td>38.890539</td>\n",
       "      <td>38.902760</td>\n",
       "      <td>38.914751</td>\n",
       "      <td>39.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lng</th>\n",
       "      <td>10693995.0</td>\n",
       "      <td>-77.031872</td>\n",
       "      <td>0.033462</td>\n",
       "      <td>-77.40</td>\n",
       "      <td>-77.044609</td>\n",
       "      <td>-77.031617</td>\n",
       "      <td>-77.013667</td>\n",
       "      <td>-76.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lat</th>\n",
       "      <td>10677232.0</td>\n",
       "      <td>38.902256</td>\n",
       "      <td>0.050493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.890496</td>\n",
       "      <td>38.902314</td>\n",
       "      <td>38.912648</td>\n",
       "      <td>39.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lng</th>\n",
       "      <td>10677232.0</td>\n",
       "      <td>-77.031463</td>\n",
       "      <td>0.091278</td>\n",
       "      <td>-77.56</td>\n",
       "      <td>-77.044661</td>\n",
       "      <td>-77.031500</td>\n",
       "      <td>-77.012808</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count       mean       std    min        25%        50%  \\\n",
       "start_lat  10693995.0  38.903306  0.026842  38.76  38.890539  38.902760   \n",
       "start_lng  10693995.0 -77.031872  0.033462 -77.40 -77.044609 -77.031617   \n",
       "end_lat    10677232.0  38.902256  0.050493   0.00  38.890496  38.902314   \n",
       "end_lng    10677232.0 -77.031463  0.091278 -77.56 -77.044661 -77.031500   \n",
       "\n",
       "                 75%    max  \n",
       "start_lat  38.914751  39.14  \n",
       "start_lng -77.013667 -76.82  \n",
       "end_lat    38.912648  39.19  \n",
       "end_lng   -77.012808   0.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                    0\n",
       "rideable_type              0\n",
       "started_at                 0\n",
       "ended_at                   0\n",
       "start_station_name    742776\n",
       "start_station_id      742776\n",
       "end_station_name      811282\n",
       "end_station_id        811282\n",
       "start_lat                  2\n",
       "start_lng                  2\n",
       "end_lat                16765\n",
       "end_lng                16765\n",
       "member_casual              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NULLs in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_col = df.select_dtypes(include=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5CB9DFCECF79AF84</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-01-01 00:08:33</td>\n",
       "      <td>2021-01-01 00:33:53</td>\n",
       "      <td>Maine Ave &amp; 9th St SW</td>\n",
       "      <td>31646.0</td>\n",
       "      <td>Rosslyn Metro / Wilson Blvd &amp; Ft Myer Dr</td>\n",
       "      <td>31015.0</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>629E059504606547</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-01-01 00:13:43</td>\n",
       "      <td>2021-01-01 00:29:34</td>\n",
       "      <td>10th &amp; U St NW</td>\n",
       "      <td>31111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E74069873161EE33</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-01-01 00:14:32</td>\n",
       "      <td>2021-01-01 00:28:45</td>\n",
       "      <td>17th &amp; Corcoran St NW</td>\n",
       "      <td>31214.0</td>\n",
       "      <td>14th &amp; Belmont St NW</td>\n",
       "      <td>31119.0</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91F95E512CABC46A</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-01-01 00:15:45</td>\n",
       "      <td>2021-01-01 00:21:20</td>\n",
       "      <td>Wilson Blvd. &amp; N. Vermont St.</td>\n",
       "      <td>31926.0</td>\n",
       "      <td>Wilson Blvd. &amp; N. Vermont St.</td>\n",
       "      <td>31926.0</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA46A05139C0EA2F</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-01-01 00:17:46</td>\n",
       "      <td>2021-01-01 00:21:00</td>\n",
       "      <td>11th &amp; Park Rd NW</td>\n",
       "      <td>31651.0</td>\n",
       "      <td>14th &amp; Newton St NW</td>\n",
       "      <td>31649.0</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  5CB9DFCECF79AF84   classic_bike  2021-01-01 00:08:33  2021-01-01 00:33:53   \n",
       "1  629E059504606547  electric_bike  2021-01-01 00:13:43  2021-01-01 00:29:34   \n",
       "2  E74069873161EE33  electric_bike  2021-01-01 00:14:32  2021-01-01 00:28:45   \n",
       "3  91F95E512CABC46A   classic_bike  2021-01-01 00:15:45  2021-01-01 00:21:20   \n",
       "4  DA46A05139C0EA2F   classic_bike  2021-01-01 00:17:46  2021-01-01 00:21:00   \n",
       "\n",
       "              start_station_name start_station_id  \\\n",
       "0          Maine Ave & 9th St SW          31646.0   \n",
       "1                 10th & U St NW          31111.0   \n",
       "2          17th & Corcoran St NW          31214.0   \n",
       "3  Wilson Blvd. & N. Vermont St.          31926.0   \n",
       "4              11th & Park Rd NW          31651.0   \n",
       "\n",
       "                           end_station_name end_station_id member_casual  \n",
       "0  Rosslyn Metro / Wilson Blvd & Ft Myer Dr        31015.0        member  \n",
       "1                                       NaN            NaN        casual  \n",
       "2                      14th & Belmont St NW        31119.0        member  \n",
       "3             Wilson Blvd. & N. Vermont St.        31926.0        member  \n",
       "4                       14th & Newton St NW        31649.0        member  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[string_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values before conversion:\n",
      " ride_id               10693997\n",
      "rideable_type                3\n",
      "started_at             9649173\n",
      "ended_at               9638365\n",
      "start_station_name         860\n",
      "start_station_id          1891\n",
      "end_station_name           865\n",
      "end_station_id            1904\n",
      "start_lat               570110\n",
      "start_lng               617671\n",
      "end_lat                 173835\n",
      "end_lng                 183886\n",
      "member_casual                2\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values before conversion\n",
    "unique_values_before = df.nunique()\n",
    "print(\"Unique values before conversion:\\n\", unique_values_before, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage before Converting dtypes:\n",
      " Index                       132\n",
      "ride_id               695109805\n",
      "rideable_type         654238494\n",
      "started_at            727191796\n",
      "ended_at              727191796\n",
      "start_station_name    740478725\n",
      "start_station_id      343549594\n",
      "end_station_name      736905216\n",
      "end_station_id        343530364\n",
      "start_lat              85551976\n",
      "start_lng              85551976\n",
      "end_lat                85551976\n",
      "end_lng                85551976\n",
      "member_casual         588169835\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Memory usage before converting\n",
    "memory_usage = df.memory_usage(deep=True)\n",
    "print(\"Memory Usage before Converting dtypes:\\n\", memory_usage, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe\n",
    "df2 = df.copy()\n",
    "\n",
    "# Convert categorical columns to category type for memory efficiency\n",
    "df2[\"rideable_type\"] = df2[\"rideable_type\"].astype(\"category\")\n",
    "df2[\"start_station_name\"] = df2[\"start_station_name\"].astype(\"category\")\n",
    "df2[\"end_station_name\"] = df2[\"end_station_name\"].astype(\"category\")\n",
    "df2[\"member_casual\"] = df2[\"member_casual\"].astype(\"category\")\n",
    "\n",
    "# Convert started_at and ended_at to datetime for memory efficiency\n",
    "df2['started_at'] = pd.to_datetime(df2['started_at'])\n",
    "df2['ended_at'] = pd.to_datetime(df2['ended_at'])\n",
    "\n",
    "# Regenerate the entire ride_id column with sequential integers and convert it\n",
    "# to a memory-efficient data type (uint32)\n",
    "df2['ride_id'] = pd.Series(range(1, len(df2) + 1), dtype='uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10693997 entries, 0 to 10693996\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             uint32        \n",
      " 1   rideable_type       category      \n",
      " 2   started_at          datetime64[ns]\n",
      " 3   ended_at            datetime64[ns]\n",
      " 4   start_station_name  category      \n",
      " 5   start_station_id    object        \n",
      " 6   end_station_name    category      \n",
      " 7   end_station_id      object        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       category      \n",
      "dtypes: category(4), datetime64[ns](2), float64(4), object(2), uint32(1)\n",
      "memory usage: 754.8+ MB\n",
      "Info of the DataFrame after conversion:\n",
      " None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check info and dtypes after conversion\n",
    "info_after = df2.info()\n",
    "print(\"Info of the DataFrame after conversion:\\n\", info_after, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values after conversion:\n",
      " ride_id               10693997\n",
      "rideable_type                3\n",
      "started_at             9649173\n",
      "ended_at               9638365\n",
      "start_station_name         860\n",
      "start_station_id          1891\n",
      "end_station_name           865\n",
      "end_station_id            1904\n",
      "start_lat               570110\n",
      "start_lng               617671\n",
      "end_lat                 173835\n",
      "end_lng                 183886\n",
      "member_casual                2\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values after conversion\n",
    "unique_values_after = df2.nunique()\n",
    "print(\"Unique values after conversion:\\n\", unique_values_after, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage after Converting dtype:\n",
      " Index                       132\n",
      "ride_id                42775988\n",
      "rideable_type          10694288\n",
      "started_at             85551976\n",
      "ended_at               85551976\n",
      "start_station_name     21485201\n",
      "start_station_id      343549594\n",
      "end_station_name       21485559\n",
      "end_station_id        343530364\n",
      "start_lat              85551976\n",
      "start_lng              85551976\n",
      "end_lat                85551976\n",
      "end_lng                85551976\n",
      "member_casual          10694215\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage after all conversions\n",
    "print(\"Memory Usage after Converting dtype:\\n\", df2.memory_usage(deep=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We reduced the in-memory footprint of the dataset to 0.22 of its original size.\n"
     ]
    }
   ],
   "source": [
    "# Calculate how much we reduced the in-memory footprint of the dataset\n",
    "reduction = df2.memory_usage(deep=True).sum() / df.memory_usage(deep=True).sum()\n",
    "print(f\"We reduced the in-memory footprint of the dataset to {reduction:.2f} of its original size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speichern neue Datei mit niedrigem Storage\n",
    "output_file =\"CBS_2021-2023_Full_minimize_storage.csv\"\n",
    "df2.to_csv(output_file, index=False)  # Neue CSV speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datei 'CBS_2021-2023_Full_2000_rows.csv' wurde erfolgreich gespeichert!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Datei einlesen (nur die ersten 2000 Zeilen)\n",
    "input_file = \"CBS_2021-2023_Full.csv\"  # Ersetze mit dem echten Dateinamen\n",
    "output_file = \"CBS_2021-2023_Full_2000_rows.csv\"\n",
    "\n",
    "df = pd.read_csv(input_file, nrows=2000)  # Nur die ersten 2000 Zeilen lesen\n",
    "df.to_csv(output_file, index=False)  # Neue CSV speichern\n",
    "\n",
    "print(f\"Die Datei '{output_file}' wurde erfolgreich gespeichert!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maze letter panther town captain math accuse food craft promote return equip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
